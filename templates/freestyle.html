{% extends "base_cassette.html" %}

{% block title %}FlowState - Freestyle{% endblock %}

{% block vertical_text %}PLAY{% endblock %}
{% block right_vertical_text %}FREE STYLE{% endblock %}
{% block red_panel %}{% endblock %}

{% block back_button %}
<button onclick="window.location.href='/'"
    class="absolute top-[100px] left-4 md:left-8 z-10 bg-secondary border-4 border-foreground px-4 py-2 font-display text-lg tracking-widest text-secondary-foreground cursor-pointer btn-3d">
    ‚óÄ BACK
</button>
{% endblock %}

{% block content_margin %}{% endblock %}

{% block extra_head %}
<style>
    @keyframes blink {
        0%, 100% { opacity: 1; }
        50% { opacity: 0; }
    }
    .animate-blink {
        animation: blink 1s step-end infinite;
    }
    #videoElement {
        transform: scaleX(-1);
        width: 100%;
        height: 100%;
        object-fit: cover;
    }
    canvas {
        transform: scaleX(-1);
    }
</style>
{% endblock %}

{% block cassette_content %}
<div class="mt-8 pr-0 md:pr-12">
    <!-- Title -->
    <div class="mb-6 flex items-center justify-between">
        <h1 class="font-display text-4xl md:text-5xl tracking-[0.25em] text-foreground leading-[0.9]">
            FREE STYLE
        </h1>
        <div class="flex gap-4 items-center">
            <button id="enableSoundBtn" onclick="initializeAudio()" class="bg-primary border-4 border-foreground px-4 py-2 font-display text-lg tracking-widest text-primary-foreground cursor-pointer btn-3d hover:translate-y-1 transition-transform">
                üîä ENABLE SOUND
            </button>
            <div id="recIndicator" class="hidden flex items-center gap-2 bg-foreground px-3 py-1 border-2 border-primary">
                <div class="w-3 h-3 rounded-full bg-primary animate-blink"></div>
                <span class="font-display text-primary tracking-widest text-sm">REC</span>
            </div>
        </div>
    </div>

    <!-- Camera Feed -->
    <div class="mb-6 border-[5px] border-foreground overflow-hidden relative" style="box-shadow: 8px 8px 0 hsl(0, 0%, 10%);">
        <img id="videoElement" src="/video_feed" />
        <canvas id="canvas" style="position: absolute; top: 0; left: 0;"></canvas>
        <!-- Hand label in top-left corner -->
        <div id="handLabel" class="absolute top-4 left-4 bg-foreground text-card border-2 border-card px-4 py-2 font-display text-xl tracking-wider" style="box-shadow: 3px 3px 0 rgba(0,0,0,0.3);">
            NO HAND
        </div>
        <div id="poseDisplay" class="absolute top-4 right-4 bg-foreground/90 text-white px-4 py-2 font-display text-2xl tracking-wider"></div>
        <!-- Gesture display at bottom -->
        <div id="gestureDisplay" class="absolute bottom-4 left-1/2 -translate-x-1/2 bg-foreground text-card border-4 border-card px-8 py-3 font-display text-3xl tracking-widest" style="box-shadow: 4px 4px 0 rgba(0,0,0,0.5);">
            NO GESTURE
        </div>
    </div>

    <!-- Instructions -->
    <div class="bg-card border-4 border-foreground p-4 mb-6" style="box-shadow: 6px 6px 0 hsl(0, 0%, 10%);">
        <div class="font-display text-sm tracking-widest text-foreground/70 mb-2">
            üìã INSTRUCTIONS
        </div>
        <ul class="text-xs font-bold tracking-wider text-foreground/80 space-y-1">
            <li>‚Ä¢ Move your hands naturally in front of the camera</li>
            <li>‚Ä¢ Practice different movements at your own pace</li>
            <li class="text-primary">‚Ä¢ Make poses ‚òùÔ∏è (E), ‚úåÔ∏è (D), ü§ü (C) to play Hot Cross Buns!</li>
            <li>‚Ä¢ Your movements are automatically tracked and analyzed</li>
        </ul>
    </div>

    <!-- Last Note Display -->
    <div id="lastNoteDisplay" class="mb-6 bg-secondary border-4 border-foreground p-4 text-center">
        <div class="font-display text-sm tracking-widest text-secondary-foreground/70 mb-2">LAST NOTE</div>
        <div id="lastNote" class="font-display text-4xl tracking-wider text-secondary-foreground">-</div>
    </div>

    <!-- AI Analysis -->
    <div class="bg-card border-4 border-foreground p-4" style="box-shadow: 6px 6px 0 hsl(0, 0%, 10%);">
        <div class="font-display text-lg tracking-widest text-foreground mb-2">
            ü§ñ AI COACH
        </div>
        <div id="analysis" class="text-sm text-foreground/80 font-mono min-h-[60px]">
            Enable audio and start recording to get live coaching feedback...
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script>
let isRecording = false;
let sessionId = null;
let audioContext = null;
let lastPose = null;
let soundEnabled = false;
let hasPlayedNote = false;

const POSE_NOTES = {
    '1': { freq: 329.63, name: 'E' },
    '2': { freq: 293.66, name: 'D' },
    '3': { freq: 261.63, name: 'C' }
};

// Load video feed from backend (MJPEG stream)
const video = document.getElementById('videoElement');

// Piano samples - using Web Audio API to create piano-like sounds
const pianoSamples = {};

// PIANO AUDIO SYSTEM - Creates realistic piano sounds
function initializeAudio() {
    if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
    }
    
    audioContext.resume().then(() => {
        soundEnabled = true;
        document.getElementById('enableSoundBtn').style.display = 'none';
        
        // Load piano samples
        loadPianoSamples();
        
        // Test sound
        setTimeout(() => playPianoNote(440, 0.2), 100);
        showToast('üéπ Piano Sound Enabled', 'Gestures will now play piano notes!');
    });
}

// Load piano samples (generate using additive synthesis for realistic piano sound)
function loadPianoSamples() {
    const notes = {
        'E': 329.63,
        'D': 293.66,
        'C': 261.63
    };
    
    // Pre-generate piano samples
    for (const [name, freq] of Object.entries(notes)) {
        pianoSamples[freq] = createPianoSample(freq);
    }
}

// Create a piano-like sound using additive synthesis
function createPianoSample(frequency) {
    const sampleRate = audioContext.sampleRate;
    const duration = 2.0; // 2 second sample
    const length = sampleRate * duration;
    const buffer = audioContext.createBuffer(1, length, sampleRate);
    const data = buffer.getChannelData(0);
    
    // Piano has rich harmonic content - fundamental + harmonics
    const harmonics = [
        { freq: 1.0, amp: 1.0 },    // Fundamental
        { freq: 2.0, amp: 0.5 },    // 2nd harmonic
        { freq: 3.0, amp: 0.3 },    // 3rd harmonic
        { freq: 4.0, amp: 0.2 },    // 4th harmonic
        { freq: 5.0, amp: 0.1 },    // 5th harmonic
        { freq: 6.0, amp: 0.05 }    // 6th harmonic
    ];
    
    // Generate waveform with harmonics
    for (let i = 0; i < length; i++) {
        const t = i / sampleRate;
        let sample = 0;
        
        // Add harmonics
        for (const h of harmonics) {
            sample += Math.sin(2 * Math.PI * frequency * h.freq * t) * h.amp;
        }
        
        // Piano envelope: fast attack, gradual decay
        const attack = Math.min(1, i / (sampleRate * 0.002)); // 2ms attack
        const decay = Math.exp(-3 * t); // Exponential decay
        const envelope = attack * decay;
        
        data[i] = sample * envelope * 0.3; // Normalize volume
    }
    
    return buffer;
}

// Auto-start on page load
window.addEventListener('load', () => {
    startPosePolling();
});

// PIANO PLAYER - Plays realistic piano sounds
function playTone(frequency, duration = 0.3) {
    playPianoNote(frequency, duration);
}

function playPianoNote(frequency, duration = 0.3) {
    if (!audioContext || !soundEnabled) return;
    
    const now = audioContext.currentTime;
    
    // Use pre-generated sample if available, otherwise create on the fly
    let source = audioContext.createBufferSource();
    if (pianoSamples[frequency]) {
        source.buffer = pianoSamples[frequency];
    } else {
        source.buffer = createPianoSample(frequency);
    }
    
    // Create gain node for volume control
    const gainNode = audioContext.createGain();
    gainNode.gain.setValueAtTime(0.4, now);
    gainNode.gain.exponentialRampToValueAtTime(0.01, now + duration);
    
    // Connect and play
    source.connect(gainNode);
    gainNode.connect(audioContext.destination);
    
    source.start(now);
    source.stop(now + duration);
}

// Pose polling
function startPosePolling() {
    const canvas = document.getElementById('canvas');
    const video = document.getElementById('videoElement');
    const ctx = canvas.getContext('2d');
    
    let pollCount = 0;
    
    setInterval(async () => {
        try {
            const response = await fetch('/api/current_pose');
            if (response.ok) {
                const data = await response.json();
                const pose = data.pose;
                const landmarks = data.landmarks;
                const handedness = data.handedness;
                
                // Debug logging every 20 polls (~2 seconds)
                pollCount++;
                if (pollCount % 20 === 0) {
                    console.log(`üìä Poll #${pollCount}: Pose=${pose}, Landmarks=${landmarks.length}, Handedness=${handedness.length}, AudioState=${audioContext?.state}, SoundEnabled=${soundEnabled}`);
                }
                
                // Always log pose changes
                if (pose && pose !== lastPose && pose !== 'None') {
                    console.log(`üéØ POSE CHANGED: ${lastPose} ‚Üí ${pose}`);
                }
                
                // Update pose display (top-right)
                document.getElementById('poseDisplay').textContent = pose || 'No pose';
                
                // Update gesture display (bottom center) with descriptive names
                const gestureDisplay = document.getElementById('gestureDisplay');
                if (pose === '1') {
                    gestureDisplay.textContent = '‚òùÔ∏è ONE FINGER';
                } else if (pose === '2') {
                    gestureDisplay.textContent = '‚úåÔ∏è TWO FINGERS';
                } else if (pose === '3') {
                    gestureDisplay.textContent = 'ü§ü THREE FINGERS';
                } else if (pose === 'palm') {
                    gestureDisplay.textContent = 'üñêÔ∏è OPEN PALM';
                } else if (pose === 'fist') {
                    gestureDisplay.textContent = '‚úä CLOSED FIST';
                } else if (pose === null || pose === '' || pose === 'None') {
                    gestureDisplay.textContent = 'NO GESTURE';
                } else {
                    gestureDisplay.textContent = pose.toUpperCase();
                }
                
                // Update hand label (top-left) - always show detected hand or no hand
                const handLabel = document.getElementById('handLabel');
                if (handedness && handedness.length > 0 && handedness[0].categoryName) {
                    const hand = handedness[0].categoryName;
                    handLabel.textContent = `${hand.toUpperCase()} HAND`;
                } else if (landmarks && Array.isArray(landmarks) && landmarks.length > 0) {
                    handLabel.textContent = 'HAND DETECTED';
                } else if (typeof landmarks === 'number' && landmarks > 0) {
                    handLabel.textContent = `HAND DETECTED (${landmarks} points)`;
                } else {
                    handLabel.textContent = 'NO HAND';
                }
                
                // Draw skeleton on canvas
                canvas.width = video.naturalWidth || 640;
                canvas.height = video.naturalHeight || 480;
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                // Only draw if landmarks is an array with data
                if (landmarks && Array.isArray(landmarks) && landmarks.length > 0) {
                    drawHandSkeleton(ctx, landmarks[0], canvas.width, canvas.height);
                }
                
                // Play note logic: play once when pose changes, reset with fist
                // Filter out null/None/empty poses
                const validPose = (pose && pose !== 'None' && pose !== 'null') ? pose : null;
                
                if (validPose === 'fist') {
                    // Fist resets the note playing flag
                    hasPlayedNote = false;
                    lastPose = 'fist';
                    console.log('üëä Fist detected - reset note playing flag');
                } else if (validPose && POSE_NOTES[validPose]) {
                    // Play note only if it's a new pose
                    if (validPose !== lastPose) {
                        console.log(`üéπ Triggering note for pose: ${validPose} (was: ${lastPose})`);
                        playNote(validPose);
                        lastPose = validPose;
                        hasPlayedNote = true;
                    }
                } else {
                    if (validPose && validPose !== lastPose) {
                        console.log(`‚ö†Ô∏è Pose ${validPose} has no note mapping`);
                    }
                    lastPose = validPose;
                }
            }
        } catch (e) {
            console.error('Pose check error:', e);
        }
    }, 100);  // Reduced to 100ms (10fps) to avoid camera stress
}

// Draw hand skeleton with green lines
function drawHandSkeleton(ctx, handLandmarks, width, height) {
    // Check if handLandmarks is valid
    if (!handLandmarks || typeof handLandmarks !== 'object') {
        console.warn('Invalid landmarks passed to drawHandSkeleton');
        return;
    }
    
    // Handle case where handLandmarks might be an object with a landmarks property
    const landmarks = Array.isArray(handLandmarks) ? handLandmarks : 
                     (handLandmarks.landmarks || handLandmarks);
    
    if (!Array.isArray(landmarks) || landmarks.length === 0) {
        console.warn('Landmarks is not an array or is empty');
        return;
    }
    
    ctx.strokeStyle = '#00ff00'; // Green color
    ctx.lineWidth = 3;
    ctx.fillStyle = '#00ff00';
    
    // Hand connections (MediaPipe hand landmark connections)
    const connections = [
        [0, 1], [1, 2], [2, 3], [3, 4],  // Thumb
        [0, 5], [5, 6], [6, 7], [7, 8],  // Index finger
        [0, 9], [9, 10], [10, 11], [11, 12],  // Middle finger
        [0, 13], [13, 14], [14, 15], [15, 16],  // Ring finger
        [0, 17], [17, 18], [18, 19], [19, 20],  // Pinky
        [5, 9], [9, 13], [13, 17]  // Palm
    ];
    
    // Draw connections
    ctx.beginPath();
    connections.forEach(([start, end]) => {
        if (landmarks[start] && landmarks[end]) {
            const startX = landmarks[start].x * width;
            const startY = landmarks[start].y * height;
            const endX = landmarks[end].x * width;
            const endY = landmarks[end].y * height;
            
            ctx.moveTo(startX, startY);
            ctx.lineTo(endX, endY);
        }
    });
    ctx.stroke();
    
    // Draw landmark points
    landmarks.forEach(landmark => {
        const x = landmark.x * width;
        const y = landmark.y * height;
        ctx.beginPath();
        ctx.arc(x, y, 5, 0, 2 * Math.PI);
        ctx.fill();
    });
}

function playNote(pose) {
    console.log('üéµ playNote called with pose:', pose);
    
    if (!audioContext) {
        console.warn('‚ùå Audio context not initialized - click ENABLE SOUND first');
        return;
    }
    
    if (!soundEnabled) {
        console.warn('‚ùå Sound not enabled - click ENABLE SOUND first');
        return;
    }
    
    const noteInfo = POSE_NOTES[pose];
    if (!noteInfo) {
        console.warn('‚ùå No note mapping for pose:', pose);
        return;
    }
    
    // Resume audio context if needed
    if (audioContext.state === 'suspended') {
        console.warn('‚ö†Ô∏è Audio context suspended - resuming...');
        audioContext.resume();
    }
    
    console.log('üéµ Playing note:', noteInfo.name, 'at', noteInfo.freq, 'Hz');
    playTone(noteInfo.freq, 0.5);
    document.getElementById('lastNote').textContent = noteInfo.name;
    
    // Visual feedback
    const gestureDisplay = document.getElementById('gestureDisplay');
    gestureDisplay.style.color = '#00ff00';
    setTimeout(() => {
        gestureDisplay.style.color = '';
    }, 200);
}

// Toast notification
function showToast(title, message, isError = false) {
    const toast = document.createElement('div');
    toast.className = `fixed top-4 right-4 bg-${isError ? 'destructive' : 'secondary'} text-${isError ? 'destructive' : 'secondary'}-foreground border-4 border-foreground p-4 btn-3d z-50`;
    toast.innerHTML = `<div class="font-display text-lg tracking-wider">${title}</div><div class="text-sm">${message}</div>`;
    document.body.appendChild(toast);
    setTimeout(() => toast.remove(), 3000);
}
</script>
{% endblock %}
